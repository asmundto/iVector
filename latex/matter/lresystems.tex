\chapter{Language Recognition systems}

\section{Language Detection vs Identification}
\label{sect:detvsid}

Identification and detection of languages are two very related tasks in language recognition. In both tasks languages are constricted to be in a set of classes. Each class can be a single language, dialect, or a set of languages, and the goal of our system is to separate these classes. In this thesis we will only look at formulations where each class is a single language and possibly one class that consists of all other languages, which we refer to as an \emph{out of set language}. We call it an \emph{open set} recognition problem When the set includes an out of set language, and \emph{closed set} otherwise. With this formulation in mind, we drop the notion of classes, and just call each class a language. 

Given a hypothesized language, a language detection system will either accept or reject the claimed language based on a set of observations. The confidence the language detection system requires for its decisions will vary on application, but we say that we accept the hypothesis if the probability that it is the hypothesized language, $l_i$, given the systems knowledge of languages, $\theta$, and observations, $S$, is greater than some threshold, $t$. The acceptance criteria can also be written as

\begin{equation}
\label{lredeceq}
p(l_i | \theta, X) \geq t.
\end{equation}
Any claim that doesn't satisfy the equation will be rejected. There are two sources of error associated with a decision in equation \ref{lredeceq}. First we can choose to accept that language $l_i$ was used in the given utterance, when it actually was another language. This is called an \emph{false accept}. The second error type is when we reject the hypothesized language even though it  was true, which is called an  \emph{false reject}. The tolerance for false accepts and false reject will vary for different applications. From equation \ref{lredeceq} we see that the errors should be inversely correlated, so there is no universally best threshold-value for any system. E.g. an recognition system that redirects phone customers to an operator that knows the customers language, could want to minimize the number of false accepts, and rather have the caller type in his language when there is much doubt.

 In language identification, our goal is just to find the most probable language from the known languages, that is
\begin{equation*}
\underset{i}{\arg \max} p(l_i | \theta, X).
\end{equation*}
This means that unless we are implementing a system for a real application, the distinction between the two language recognition problems aren't that important so long as we find $P(l_i | \theta, X)$. What is more important is that the model of the languages, $\theta$, is suited to distinguish languages.

\subsection{Performance Measures}

blabla

\section{System Overview}
\label{sect:sysoverview}

It could be possible to write a set of rules that scores the utterances against languages. The approach taken by many recent language recognition systems is to build a statistical model from training data. Without speculating on how much time it would take to create a rule based system, a statistical driven system should at least be easier to extend to new languages.


\section{Phoneme recognizer}
\label{sect:phnrec}

In a PRLM recognition system, we first transform the speech signal to a phoneme sequence or string. This is done by a phoneme recognizer. With the many-to-one mapping by the phoneme recognizer we hope that there still is enough information about the language identity of the utterance, while the computational requirements for further processing will benefit from the reduced complexity of the problem. Phone recognizers can utilize many of the techniques used in speech recognition,  where words often are recognized by their phoneme sequence \cite[p. 414]{talegk}. Here we will only present one such approach.

The speech signal is first split into short frames using a window function to reduce spectrum leakage \cite[257]{talegk}. For each frame we can calculate the Mel-Frequency Cepstral Coefficients (MFCC). The transform takes the spectrum of the windowed signal through a set of filter banks that are spaced to approximate the Mel-frequency scale \cite[314]{talegk}. After taking the logarithm of the filter outputs, we use the discrete cosine transform to get the cepstral coefficients. The whole process approximates the way the human auditory system responds to sound, which means that it should be suited for automatic phoneme recognition as well \cite[314]{talegk}.Patterns in the cepstral coefficients when uttering a given phoneme can then be learned using labeled training data to train Gaussian Mixture Models (this is presented in section \ref{sect:backendscoring} for recognizing score-vectors).

The size of each frame is limited, in order to make the speech signal in each frame approximately stationary, but this doesn't mean that the neighboring frames have no information about the phoneme uttered in the current frame. Many recent phone recognizers use long temporal context techniques to capture the evolution of the signal outside of the frame \cite[p. 8]{butphnrec}. One such technique is to concatenate the $n$ cepstral coefficients in the current frame together with the $k$ past and future frames \cite[9]{butphnrec}, resulting in a $n(2k+1)$-dimensional feature vector. The high number of parameters in the long temporal context feature vector can make it difficult to train the phoneme recognizer without having huge amounts of training material. By assuming that the coefficients in past frames are independent of future frames, we can split the vector into a left and right context. This enables us to first classify each context separately, and then merge the results into a final decision of what phoneme was spoken \cite[p. 36]{butphnrec}. We can use GMMs for both classifying steps. The halving of the feature vector then increases the probability of observing similar features in the training set, reducing the need for much training data.


Et eller annet om at språk på fonemgjennkjenneren ikke trenger å stemme


\section{Language models}
\label{sect:basiclangmodel}

The responsibility of the language model is to output a single score per language from a phoneme sequence $S$. Since our final recognition decision will be based on the probability that an utterance belongs to a language, $p(l_i, | S)$, it seems natural to have the scores approximate that probability. This is a somewhat strict requirement for systems as described in section \ref{sect:sysoverview} since the scores will be further processed by the backend. At the very least, a good language model should give scores that are easily transformable to an estimate of this probability. 

In order for the system to perform well for languages with limited available training data, it will be beneficial that the language model is easily trained. A too complex model will not be able to see patterns in the data, it will instead be over-fitted to explain each utterance independently which makes it unfit to score utterances outside of the training set \cite[311]{information}. Over-fitting can be reduced by using a larger training set \cite[147]{machinelearningbook}, but it is clearly an undesirable feature for a language models. This is also the reason why we need a separate data set to evaluate the recognition system. The systems recognition performance on the data it was trained for will not necessarily extend to unseen data.

If we introduce the notion that training and test data are generated from a random process, the systems ability to correctly estimate $p(l_i | S)$, and thereby make correct recognition decisions, will be given by two error sources called model \emph{bias} and \emph{variance} \cite[149]{machinelearningbook}. \emph{Bias} is high if the system consistently over- or underestimate $p(l_i | S)$ for some documents regardless of the training set. In this way it represents the systems inability to correctly predict certain documents. Model \emph{variance} is the variance in the probability estimate of an utterance belonging to a language when the model is trained with different data. It represents the systems sensitivity to noise in the training data. Over-fitting is a symptom of a high variance system where the model is only expected to give correct probability estimates for utterances that are very close to a training utterance. A system with limited training data can generally not have both low variance and bias \cite[312]{information}, so a concession between the two errors has to be made.

This was only a shallow introduction to language models due to the variety of techniques used in language recognition systems. A more detailed survey will be given when we discuss specific language models in section \ref{sect:basetrain} and ???.









\section{Back-end Calibration of Score Vectors}
\label{sect:backendscoring}

The back-end will calibrate the scores from the language model into the posterior, $p(l_i | S, \theta)$, so that so that they can be applied to the recognition decisions discussed in section \ref{sect:detvsid}. Like the language model, this calibration can be trained using real data. A separate calibration step allows us to ignore application dependent information like what other languages should the system recognize, and the prior probability of a user speaking each language. The language models for each language can then be trained independently since it only needs to return some number that in some way correlates with the posterior probability for it's language. Even if the language model is trained to return estimates of the posterior, there may still be some benefits calibrating the score vectors \cite[820]{lidbok} as there might exist patterns in the scores that can be exploited. Furthermore, the back-end can be used to fuse scores for an utterance from multiple systems using different phoneme recognizers or language models. The fused system is then expected to perform better than each of the individual systems as long as the errors each system makes are somewhat uncorrelated \cite[818]{lidbok}.

\subsection{Gaussian Backend}
\label{sect:gmmscore}

It is likely that the best calibration method will depend on the nature of the score-vectors given from the language models. A very flexible tool to perform calibration that impose little demands on the score vector is to use a multivariate Gaussian mixture model (GMM). With this framework, the score vector, $\mathbf{y}$, for a given language is assumed to be produced from a generative statistical model. The likelihood of a $r$-dimensional Gaussian component $k$ to produce a score vector $\mathbf{y}$ is then

\begin{equation}
\label{gmmeq}
p(\mathbf{y} | \mathbf{\mu}_k, \mathbf{\Sigma}_k, K = k) = \frac{1}{(2\pi)^{r/2}|\mathbf{\Sigma}_k|^{1/2}}\exp(-\frac{1}{2}(\mathbf{y}-\mathbf{\mu_k})^T\mathbf{\Sigma}_k^{-1}(\mathbf{x}-\mathbf{\mu_k}))
\end{equation}
where $\mathbf{\mu_k}$ is the $r$-dimensional mean of the score vectors produced by the mixture, $\mathbf{\Sigma}_k$ is the covariance of the mixture and $|\mathbf{\Sigma}_k|$ it's determinant \cite[p. 94]{talegk}. From Bayes rule we have that
\begin{align}
p(K=k | \mathbf{\mu}_k, \mathbf{\Sigma}_k, \mathbf{y}) &= 
\frac{p(\mathbf{y} | \mu_k, \Sigma_k, K= k) \cdot p(K=k )}{p(\mathbf{y})} \nonumber \\
&= \frac{p(\mathbf{y} | \mu_k, \sigma_k, K=k) \cdot p(K=k)}{\sum_{\forall i \in K} p(\mathbf{y} | \mu_i, \Sigma_i, K=i) \cdot p(K=i)} \label{gmmchoose}
\end{align}
where $p(K=k)$ is the prior probability of the score vector being generated from mixture $k$. If we know what mixture each score vector in a training set belongs to, then $\mathbf{\mu}_k$ can be estimated as
\begin{equation}
\label{muest}
\mathbf{\mu}_k = \operatorname{E}(\mathbf{y} | \mathbf{y} \in k)
\end{equation}
and $\mathbf{\Sigma}_k$ as
\begin{equation}
\label{sigmaest}
\mathbf{\Sigma}_k = \operatorname{E}\left( (\mathbf{y}-\mathbf{\mu}_k)(\mathbf{y}-\mu_k)^T | \mathbf{y} \in k \right)
\end{equation}
where $E(a|b)$ is the conditional expectation \cite[p. 94]{talegk}. The power of the Gaussian mixture model we have now described is that it is enable to model any probability distribution \cite[p. 95]{talegk}, which means that it is applicable to any type of score-vector. Even for a training set, we will generally only know the language of an utterance, but not the mixture the score vector belongs to. This means that equation \ref{muest} and \ref{sigmaest} cannot directly be solved. We can still estimate the parameters using the iterative EM-algorithm covered in section \ref{sect:emgmmest}. With one mixture per language, equation \ref{muest} and \ref{sigmaest} can be solved by noting that $\mathbf{y} \in k$ is equivalent to that the score vector stems from the given language, $l_i$, and $p(K=k)$ is the prior for the language. We can then use $p(L=l_i | \mu_i, \Sigma_i, \mathbf{y})$ given in equation \ref{gmmchoose} to label unknown utterances.


\subsection{Gaussian Mixture Parameter Estimation Using Expectation Maximization}
\label{sect:emgmmest}

In the EM-algorithm, the number of mixtures per language is assumed to be fixed to some value. Initial values for $\mu$, $\Sigma$ and priors for mixtures are random or from some crude estimate. The presented algorithm is from \cite[o. 439]{machinelearningbook}

For each step we first estimate the probability that each score vector is generated from each of the mixtures given the language 
\begin{equation}
\label{emprobest}
p(K=k | \mu_k, \Sigma_k, \mathbf{y}, l_i) = \frac{p(\mathbf{y} | \mu_k, \Sigma_k, K=k, l_i)\cdot p(K=k | l_i)}{\sum_{\forall i \in k}
p(\mathbf{y} | \mu_k, \Sigma_k, K=k, l_i)\cdot p(K=k | l_i)}.
\end{equation}
This can be seen as an extension of equation \ref{gmmchoose}. The probaiblity that a score stems from mixture $k$,  will then be used to weight the contribution of score vectors to the estimates for $\mu_k$ and $\Sigma_k$. The new value for $\mu_k$, called $\mu_k(\text{NEW})$ is given by
\begin{equation}
\label{emmuest}
\mu_k(\text{NEW}) = \frac{1}{\hat{N}_k}\sum_{\forall \mathbf{y} \in l_i} p(K=k | \mu_k, \Sigma_k, \mathbf{y}, l_i)\mathbf{y}.
\end{equation}
The new mean estimates will then be used to calculate the new covariance, $\Sigma_k(\text{NEW})$, as

\begin{equation}
\label{emsigmaest}
\mathbf{\Sigma}_k(\text{NEW}) = \frac{1}{\hat{N}_k}\sum_{\forall \mathbf{y} \in l_i} p(K=k | \mu_k, \Sigma_k, \mathbf{y}, l_i)(\mathbf{y}-\mu_k(\text{NEW}))(\mathbf{y}-\mu_k(\text{NEW})^T
\end{equation}
where $\hat{N}_k$ is 
\begin{equation}
\label{emnkest}
\hat{N}_k = \sum_{\forall \mathbf{y} \in l_i} p(K=k | \mu_k, \Sigma_k, \mathbf{y}, l_i).
\end{equation}
We can then update the probability mass given language for each cluster using the new means and variances,
\begin{equation}
\label{empriorest}
p(K=k | l_i) = \frac{\sum_{\forall \mathbf{y} \in l_i}p(K=k | \mu_k(\text{NEW}), \Sigma_k(\text{NEW}), \mathbf{y}, l_i)}{\sum_{\forall \mathbf{y} \in l_i} 1}.
\end{equation}
These steps of solving equations \ref{emprobest}, \ref{emmuest}, \ref{emsigmaest}, \ref{emnkest} and \ref{empriorest} are repeated until some convergence criterion is met. Recognition decisions will then be made by evaluating the probability that the score stems from any of the languages mixtures
\begin{equation}
\label{emgmmchoose}
p(l_i | \mu, \Sigma, \mathbf{y}) = \sum{\forall k \in l_i} p(K=k | \mu_k, \Sigma_k, \mathbf{y}, l_i)\cdot p(l_i).
\end{equation}

It turns out that the best fitted model to any training data would be to have as many mixtures as training vectors, each with a covariance of 0. This is clear since $\mathbf{y}$ is continuous, so making the GMM generate only a discrete set of vectors is the only way to get a non-zero probability of generating exactly $\mathbf{y}$. Such a model would clearly be over-fitted to the training data. In order to avoid a model with too high variance, the number of mixtures per language must be carefully constrained.
